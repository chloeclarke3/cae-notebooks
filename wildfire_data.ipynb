{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1559cdbd-edd2-4c77-a61c-428159453a04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from climakitae.core.data_interface import (\n",
    "    get_data_options, \n",
    "    get_subsetting_options, \n",
    "    get_data\n",
    ")\n",
    "# import climakitae as ck\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import time\n",
    "from pyproj import Transformer\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import contextily as cx\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed0cfd4-6677-4933-8c94-e64f93c9aa39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variables_units = (\"Fosberg fire weather index\",\"[0 to 100]\",\"Dynamical\",\"hourly\",[2.0])\n",
    "variable, unit,downscale,timescale,GWL = variables_units\n",
    "print(variable,unit,downscale,timescale,GWL)\n",
    "print(f\"Processing variable: {variable}\")\n",
    "ds = get_data(\n",
    "    variable=variable,\n",
    "    # units=unit,\n",
    "    downscaling_method=downscale,\n",
    "    resolution=\"3 km\",\n",
    "    timescale=timescale,\n",
    "    cached_area=\"Southern California Edison\",\n",
    "    approach=\"Warming Level\",\n",
    "    warming_level_window=15,\n",
    "    warming_level=GWL\n",
    ")\n",
    "\n",
    "hours_in_year = 365 * 24\n",
    "# Calculate the hour of the year\n",
    "hour_of_year = ds['time_delta'].values % hours_in_year\n",
    "# Assign the new hour_of_year coordinate to the dataset\n",
    "ds = ds.assign_coords(hour_of_year=('time_delta', hour_of_year))\n",
    "print(ds)\n",
    "ds = ds.drop_vars(['landmask', 'lakemask'])\n",
    "hourly_mean = ds.groupby('hour_of_year').mean(dim='time_delta', skipna=True)\n",
    "print(hourly_mean)\n",
    "del ds\n",
    "hours_in_month = np.array([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]) * 24\n",
    "cumulative_hours = np.cumsum(hours_in_month)\n",
    "# Function to map hour_of_year to month\n",
    "def hour_to_month(hour):\n",
    "    return np.searchsorted(cumulative_hours, hour) + 1\n",
    "\n",
    "Apply the function to calculate the month for each hour_of_year\n",
    "\n",
    "print(hourly_mean)\n",
    "months = hour_to_month(hourly_mean['hour_of_year'].values)\n",
    "hourly_mean = hourly_mean.assign_coords(month=('hour_of_year', months))\n",
    "\n",
    "monthly_max = hourly_mean.groupby('month').max(dim='hour_of_year', skipna=True)\n",
    "print(monthly_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19efc6-f0cd-430f-9865-29acc2993dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = [10,50,90]\n",
    "percentile_values_ts = {p: hourly_mean.quantile(p / 100.0, dim='simulation', skipna=True) for p in percentiles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f761b-57b7-4086-8d88-f5f46457c068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfec247-9adf-408e-ad35-35096fba7951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "monthly_max.to_netcdf('Fosberg fire weather index_GWL2.0_MonthlyMax.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4253ecb-522c-45a8-8841-372465e8e378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e793a1e5-9146-4e3c-97fe-b1e6eb105e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10: <xarray.DataArray np.str_('Fosberg fire weather index') (warming_level: 1,\n",
      "                                                         hour_of_year: 8760,\n",
      "                                                         y: 240, x: 149)> Size: 3GB\n",
      "dask.array<getitem, shape=(1, 8760, 240, 149), dtype=float64, chunksize=(1, 117, 240, 149), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * warming_level  (warming_level) float64 8B 2.0\n",
      "  * x              (x) float64 1kB -4.236e+06 -4.233e+06 ... -3.792e+06\n",
      "  * y              (y) float64 2kB 5.899e+05 5.929e+05 ... 1.304e+06 1.307e+06\n",
      "    lat            (y, x) float32 143kB 31.49 31.5 31.52 ... 39.18 39.19 39.21\n",
      "    lon            (y, x) float32 143kB -117.7 -117.7 -117.7 ... -118.2 -118.2\n",
      "  * hour_of_year   (hour_of_year) float64 70kB 0.0 1.0 ... 8.758e+03 8.759e+03\n",
      "    quantile       float64 8B 0.1\n",
      "Attributes:\n",
      "    variable_id:           fosberg_index_derived\n",
      "    extended_description:  Fire weather index using meteorological inputs (te...\n",
      "    units:                 [0 to 100]\n",
      "    data_type:             Gridded\n",
      "    resolution:            3 km\n",
      "    frequency:             hourly\n",
      "    location_subset:       ['Southern California Edison']\n",
      "    approach:              Warming Level\n",
      "    downscaling_method:    Dynamical\n",
      "    warming_level_window:  +/- 15 years from centered year\n",
      "    institution:           Multiple\n",
      "    grid_mapping:          Lambert_Conformal, 50: <xarray.DataArray np.str_('Fosberg fire weather index') (warming_level: 1,\n",
      "                                                         hour_of_year: 8760,\n",
      "                                                         y: 240, x: 149)> Size: 3GB\n",
      "dask.array<getitem, shape=(1, 8760, 240, 149), dtype=float64, chunksize=(1, 117, 240, 149), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * warming_level  (warming_level) float64 8B 2.0\n",
      "  * x              (x) float64 1kB -4.236e+06 -4.233e+06 ... -3.792e+06\n",
      "  * y              (y) float64 2kB 5.899e+05 5.929e+05 ... 1.304e+06 1.307e+06\n",
      "    lat            (y, x) float32 143kB 31.49 31.5 31.52 ... 39.18 39.19 39.21\n",
      "    lon            (y, x) float32 143kB -117.7 -117.7 -117.7 ... -118.2 -118.2\n",
      "  * hour_of_year   (hour_of_year) float64 70kB 0.0 1.0 ... 8.758e+03 8.759e+03\n",
      "    quantile       float64 8B 0.5\n",
      "Attributes:\n",
      "    variable_id:           fosberg_index_derived\n",
      "    extended_description:  Fire weather index using meteorological inputs (te...\n",
      "    units:                 [0 to 100]\n",
      "    data_type:             Gridded\n",
      "    resolution:            3 km\n",
      "    frequency:             hourly\n",
      "    location_subset:       ['Southern California Edison']\n",
      "    approach:              Warming Level\n",
      "    downscaling_method:    Dynamical\n",
      "    warming_level_window:  +/- 15 years from centered year\n",
      "    institution:           Multiple\n",
      "    grid_mapping:          Lambert_Conformal, 90: <xarray.DataArray np.str_('Fosberg fire weather index') (warming_level: 1,\n",
      "                                                         hour_of_year: 8760,\n",
      "                                                         y: 240, x: 149)> Size: 3GB\n",
      "dask.array<getitem, shape=(1, 8760, 240, 149), dtype=float64, chunksize=(1, 117, 240, 149), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * warming_level  (warming_level) float64 8B 2.0\n",
      "  * x              (x) float64 1kB -4.236e+06 -4.233e+06 ... -3.792e+06\n",
      "  * y              (y) float64 2kB 5.899e+05 5.929e+05 ... 1.304e+06 1.307e+06\n",
      "    lat            (y, x) float32 143kB 31.49 31.5 31.52 ... 39.18 39.19 39.21\n",
      "    lon            (y, x) float32 143kB -117.7 -117.7 -117.7 ... -118.2 -118.2\n",
      "  * hour_of_year   (hour_of_year) float64 70kB 0.0 1.0 ... 8.758e+03 8.759e+03\n",
      "    quantile       float64 8B 0.9\n",
      "Attributes:\n",
      "    variable_id:           fosberg_index_derived\n",
      "    extended_description:  Fire weather index using meteorological inputs (te...\n",
      "    units:                 [0 to 100]\n",
      "    data_type:             Gridded\n",
      "    resolution:            3 km\n",
      "    frequency:             hourly\n",
      "    location_subset:       ['Southern California Edison']\n",
      "    approach:              Warming Level\n",
      "    downscaling_method:    Dynamical\n",
      "    warming_level_window:  +/- 15 years from centered year\n",
      "    institution:           Multiple\n",
      "    grid_mapping:          Lambert_Conformal}\n"
     ]
    }
   ],
   "source": [
    "del ds\n",
    "hourly_mean = hourly_mean.drop_vars(['landmask', 'lakemask'])\n",
    "percentiles = [10,50,90]\n",
    "percentile_values_ts = {p: hourly_mean.quantile(p / 100.0, dim='simulation', skipna=True) for p in percentiles}\n",
    "print(percentile_values_ts)\n",
    "# hourly_mean.to_netcdf('Fosberg fire weather index_GWL2.0_8760_climo.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efad4eeb-d5fa-46f2-bb86-9466d0ebbfa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "percentile_values_ts[10].to_netcdf('Fosberg fire weather index_GWL2.0_8760_climo_GWL2.0_10th.nc')\n",
    "# percentile_values_ts[50].to_netcdf('Fosberg fire weather index_GWL2.0_8760_climo_GWL2.0_50th.nc')\n",
    "# percentile_values_ts[90].to_netcdf('Fosberg fire weather index_GWL2.0_8760_climo_GWL2.0_90th.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd8980-ad3a-4a61-9c2e-9159a2e71b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dec40aa7-b398-4abc-87da-4147966c4a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "percentiles = [10,50,90]\n",
    "percentile_values_ts = {p: hourly_mean.quantile(p / 100.0, dim='simulation', skipna=True) for p in percentiles}\n",
    "percentile_values = {p: monthly_max.quantile(p / 100.0, dim='simulation', skipna=True) for p in percentiles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae678b-2c78-4dfa-afc9-fe27eb5733b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c16c91-33d9-42fb-ac59-aa88044207bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea7046e-6631-4ca5-bad6-45cdda05cd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d351380-7ca8-4946-9448-ead235700b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e2a2f9-9d03-4676-b1e5-eca55a11e6e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precipitation (total) inches Statistical daily [1.0, 1.5, 2.0]\n",
      "Processing variable: Precipitation (total)\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!!! Returned data array is huge. Operations could take 10x to infinity longer than 1GB of data !!!\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "WARNING FOR WARMING LEVELS APPROACH\n",
      "-----------------------------------\n",
      "There may be NaNs in your data for certain simulation/warming level combinations if the warming level is not reached for that particular simulation before the year 2100. \n",
      "\n",
      "This does not mean you have missing data, but rather a feature of how the data is combined in retrieval to return a single data object. \n",
      "\n",
      "If you want to remove these empty simulations, it is recommended to first subset the data object by each individual warming level and then dropping NaN values.\n",
      "<xarray.DataArray np.str_('Precipitation (total)') (warming_level: 3,\n",
      "                                                    time_delta: 10950,\n",
      "                                                    lat: 171, lon: 196,\n",
      "                                                    simulation: 129)> Size: 568GB\n",
      "dask.array<concatenate, shape=(3, 10950, 171, 196, 129), dtype=float32, chunksize=(1, 41, 114, 119, 1), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * warming_level  (warming_level) float64 24B 1.0 1.5 2.0\n",
      "  * lat            (lat) float32 684B 33.17 33.2 33.23 ... 38.42 38.45 38.48\n",
      "  * lon            (lon) float32 784B -120.2 -120.2 -120.2 ... -114.2 -114.1\n",
      "  * time_delta     (time_delta) float64 88kB -5.475e+03 -5.474e+03 ... 5.474e+03\n",
      "    spatial_ref    int64 8B 0\n",
      "    centered_year  (warming_level, simulation) int64 3kB 2014 2013 ... 2039 2040\n",
      "  * simulation     (simulation) <U48 25kB 'LOCA2_ACCESS-CM2_r1i1p1f1_historic...\n",
      "Attributes:\n",
      "    variable_id:           pr\n",
      "    extended_description:  Total precipitation. Computed by summing total gri...\n",
      "    units:                 inches\n",
      "    data_type:             Gridded\n",
      "    resolution:            3 km\n",
      "    frequency:             daily\n",
      "    location_subset:       ['Southern California Edison']\n",
      "    approach:              Warming Level\n",
      "    downscaling_method:    Statistical\n",
      "    warming_level_window:  +/- 15 years from centered year\n",
      "    institution:           UCSD\n"
     ]
    }
   ],
   "source": [
    "variables_units = (\"Precipitation (total)\", \"inches\",\"Statistical\",\"daily\",[1.0,1.5,2.0])\n",
    "variable, unit,downscale,timescale,GWL = variables_units\n",
    "print(variable,unit,downscale,timescale,GWL)\n",
    "print(f\"Processing variable: {variable}\")\n",
    "ds = get_data(\n",
    "    variable=variable,\n",
    "    units=unit,\n",
    "    downscaling_method=downscale,\n",
    "    resolution=\"3 km\",\n",
    "    timescale=timescale,\n",
    "    cached_area=\"Southern California Edison\",\n",
    "    approach=\"Warming Level\",\n",
    "    warming_level_window=15,\n",
    "    warming_level=GWL\n",
    ")\n",
    "print(ds)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
