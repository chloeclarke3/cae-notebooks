{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c25dc-4806-4d03-a608-f6d713a49462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from climakitae.core.data_interface import (\n",
    "    get_data_options, \n",
    "    get_subsetting_options, \n",
    "    get_data\n",
    ")\n",
    "# import climakitae as ck\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import time\n",
    "from pyproj import Transformer\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import contextily as cx\n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a274d1b2-6e83-4914-9d6f-e4f80b955e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def climo_calc(ds, variable, warming_levels, percentiles):\n",
    "    # Define the base month and center point (e.g., January 2000)\n",
    "    base_month = 1  # January\n",
    "\n",
    "    # Create a new coordinate for month\n",
    "    months = (base_month + ds['time_delta'].values) % 12\n",
    "    months[months == 0] = 12  # Ensure months are in the range [1, 12]\n",
    "    ds = ds.assign_coords(month=('time_delta', months))\n",
    "\n",
    "    # Group by the new month coordinate and calculate the mean\n",
    "    print(f\"Calculating monthly climatology for {variable}...\")\n",
    "    climatology_start_time = time.time()\n",
    "    climatology = ds.groupby('month').mean(dim='time_delta', skipna=True)\n",
    "\n",
    "    if variable == \"Precipitation (total)\":\n",
    "        days_in_month = np.array([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]) \n",
    "\n",
    "        # Convert monthly total precipitation to daily average within each month\n",
    "        climatology = climatology / xr.DataArray(days_in_month, dims=[\"month\"])\n",
    "        climatology.attrs['extended_description'] = 'average daily precip'\n",
    "\n",
    "        time_treatment = \"avg.\"\n",
    "\n",
    "    climatology.load()\n",
    "    print(climatology)\n",
    "\n",
    "    print(f\"Monthly climatology for {variable} calculated in {time.time() - climatology_start_time:.2f} seconds.\")\n",
    "\n",
    "    # Calculate the specified percentiles\n",
    "    print(f\"Calculating percentiles for time series {variable}...\")\n",
    "    percentiles_start_time = time.time()\n",
    "    percentile_values_ts = {p: ds.quantile(p / 100.0, dim='simulation', skipna=True) for p in percentiles}\n",
    "    print(f\"Percentiles for {variable} calculated in {time.time() - percentiles_start_time:.2f} seconds.\")\n",
    "\n",
    "    # Calculate the specified percentiles\n",
    "    print(f\"Calculating percentiles for climo {variable}...\")\n",
    "    percentiles_start_time = time.time()\n",
    "    percentile_values = {p: climatology.quantile(p / 100.0, dim='simulation', skipna=True) for p in percentiles}\n",
    "    print(f\"Percentiles for {variable} calculated in {time.time() - percentiles_start_time:.2f} seconds.\")\n",
    "\n",
    "\n",
    "    print(f\"Saving NetCDF files for {variable}...\")\n",
    "    netcdf_saving_start_time = time.time()\n",
    "    for level in warming_levels:\n",
    "        percentile_values[percentiles[0]].sel(warming_level=level).to_netcdf(f'{variable}_GWL{level}_{percentiles[0]}th.nc')\n",
    "        percentile_values[percentiles[1]].sel(warming_level=level).to_netcdf(f'{variable}_GWL{level}_{percentiles[1]}th.nc')  \n",
    "        percentile_values[percentiles[2]].sel(warming_level=level).to_netcdf(f'{variable}_GWL{level}_{percentiles[2]}th.nc')  \n",
    "    print(f\"NetCDF files for {variable} saved in {time.time() - netcdf_saving_start_time:.2f} seconds.\")\n",
    "\n",
    "    print(f\"Finished processing {variable} in {time.time() - start_time:.2f} seconds.\")\n",
    "    \n",
    "\n",
    "def process_variable(variable_unit):\n",
    "    variable, unit,downscale,timescale,GWL = variable_unit\n",
    "    print(f\"Processing variable: {variable}\")\n",
    "    ds_start_time = time.time()\n",
    "    ds = get_data(\n",
    "        variable=variable,\n",
    "        units=unit,\n",
    "        downscaling_method=downscale,\n",
    "        resolution=\"3 km\",\n",
    "        timescale=timescale,\n",
    "        cached_area=\"Southern California Edison\",\n",
    "        approach=\"Warming Level\",\n",
    "        warming_level_window=15,\n",
    "        warming_level=GWL\n",
    "    )\n",
    "    print(f\"Data retrieved for {variable} in {time.time() - ds_start_time:.2f} seconds.\")\n",
    "    climo_calc(ds, variable, GWL, [10, 50, 90])\n",
    "\n",
    "def get_multiple_data(variables_units):\n",
    "    for variable_unit in variables_units:\n",
    "        process_variable(variable_unit)\n",
    "\n",
    "variables_units = [\n",
    "    (\"Precipitation (total)\", \"inches\",\"Statistical\",\"monthly\",[1.0,1.5,2.0]),\n",
    "    (\"Maximum air temperature at 2m\", \"degF\",\"Statistical\",\"monthly\",[1.0,1.5,2.0]),\n",
    "    (\"Minimum air temperature at 2m\", \"degF\",\"Statistical\",\"monthly\",[1.0,1.5,2.0]),\n",
    "]\n",
    "\n",
    "get_multiple_data(variables_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35c86d-ab36-4ecf-9596-6667c686f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_dir = os.getcwd()\n",
    "print(_dir)\n",
    "_loc_files = glob.glob(_dir + '/*.nc')\n",
    "print(_loc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18089b92-d38a-43dc-aee7-965b676672a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store data arrays\n",
    "precipitation_data = []\n",
    "min_temp_data = []\n",
    "max_temp_data = []\n",
    "\n",
    "# Process each file based on the variable name\n",
    "for file_path in _loc_files:\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    variable_name = list(ds.data_vars.keys())[0]\n",
    "        \n",
    "    if 'xarray_dataarray_variable' in variable_name:\n",
    "        # Calculate the average over the month dimension for precipitation\n",
    "        avg_precipitation = ds.mean(dim='month',skipna=True)\n",
    "        variable_name2 = f'Avg. Daily Precip(in)GWL{ds['warming_level'].values}_{ds['quantile'].values*100}%'\n",
    "        avg_precipitation = avg_precipitation.rename({variable_name: variable_name2})\n",
    "        avg_precipitation=avg_precipitation.drop_vars(['quantile', 'warming_level'])\n",
    "        precipitation_data.append(avg_precipitation)\n",
    "        \n",
    "    elif 'Minimum air temperature' in variable_name:\n",
    "        # Calculate the minimum over the month dimension for minimum air temperature\n",
    "        min_temp = ds.min(dim='month',skipna=True)\n",
    "        variable_name2 =  f'Min air temp(DegF)GWL{ds['warming_level'].values}_{ds['quantile'].values*100}%'\n",
    "        min_temp = min_temp.rename({variable_name: variable_name2})\n",
    "        min_temp=min_temp.drop_vars(['quantile', 'warming_level'])\n",
    "        min_temp_data.append(min_temp)\n",
    "        \n",
    "    elif 'Maximum air temperature' in variable_name:\n",
    "        # Calculate the maximum over the month dimension for maximum air temperature\n",
    "        max_temp = ds.max(dim='month',skipna=True)\n",
    "        variable_name2 = f'Max air temp(DegF)GWL{ds['warming_level'].values}_{ds['quantile'].values*100}%'\n",
    "        max_temp = max_temp.rename({variable_name: variable_name2})\n",
    "        max_temp=max_temp.drop_vars(['quantile', 'warming_level'])\n",
    "        max_temp_data.append(max_temp)\n",
    "        \n",
    "\n",
    "precipitation_data = xr.merge(precipitation_data)\n",
    "precipitation_data_df = precipitation_data.to_dataframe().reset_index()\n",
    "precipitation_data_df.dropna(inplace=True)\n",
    "\n",
    "min_temp_data = xr.merge(min_temp_data)\n",
    "min_temp_data_df = min_temp_data.to_dataframe().reset_index()\n",
    "min_temp_data_df.dropna(inplace=True)\n",
    "\n",
    "max_temp_data = xr.merge(max_temp_data)\n",
    "max_temp_data_df = max_temp_data.to_dataframe().reset_index()\n",
    "max_temp_data_df.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d81df3-9b80-41db-91dc-f9f688e4f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file with subset of locations\n",
    "locations_df = pd.read_csv('~/cae-notebooks/2026_CRE_Asset_Locs_modelLocs.csv')\n",
    "\n",
    "# Subset the data based on 'model lat' and 'model lon'\n",
    "subset_precipitation_df = precipitation_data_df.merge(locations_df, left_on=['lat', 'lon'], right_on=['model lat', 'model lon'])\n",
    "subset_min_temp_df = min_temp_data_df.merge(locations_df, left_on=['lat', 'lon'], right_on=['model lat', 'model lon'])\n",
    "subset_max_temp_df = max_temp_data_df.merge(locations_df, left_on=['lat', 'lon'], right_on=['model lat', 'model lon'])\n",
    "\n",
    "subset_precipitation_df.to_csv('2026CAVA_CREAssets_Precip.csv')\n",
    "subset_min_temp_df.to_csv('2026CAVA_CREAssets_MinTemp.csv')\n",
    "subset_max_temp_df.to_csv('2026CAVA_CREAssets_MaxTemp.csv')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "climakitae",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python climakitae (Local)",
   "language": "python",
   "name": "climakitae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
